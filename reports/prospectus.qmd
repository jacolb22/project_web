---
title: "Prospectus"
date-modified: today
date-format: medium
author:
  - name: "Logan Jacobs"
    email: jacolb22@wfu.edu
    affiliation: "Wake Forest University"
abstract: |
  This is a sample prospectus. It is a work in progress and will be updated as needed as the semester progresses.
keywords:
  - prospectus
  - sample
citation: true
bibliography: ../bibliography.bib
editor: 
  markdown: 
    wrap: 72
---

# Introduction

This section introduces the topic of the prospectus, its relevance, and
specific research question(s) or hypothesis(es) that will be addressed.

## Literature review

### Intensificatory Tautology

The aim of the first study: "Intensificatory Tautology in the History of
English: A Corpus-based Study" by Victorina González-Díaz is exploratory
in nature, and concerns the development and establishment of
"intensificatory tautology" which is simply intensifying the current
meaning of a phrase or sentence without adding any more meaning. It
focuses specifically on size-adjective clusters (phrases like "great
big" and "little tiny") in the history of the English language. The
findings of this study indicate that size-adjective clusters emerged in
Late Middle English after a functional-structural reorganization of noun
phrases. This became more productive in Early Modern English, and
expanded in Present-Day English, especially in informal and spoken
settings. This study used many corpora including: the PENN collection,
the ARCHER corpus, the British National Corpus (BNC), the Early English
Books Online (EEBO) corpus, Mandeville’s travels, and Celia Fiennes’
travelogue. The analyzing methodology was corpus-based, and used part of
speech-tagged text as well as a general search for two consecutive
adjectives to prune the data to a manageable level, and the rest was
manually sorted through. The study also used statistical methods such as
MI scores and T-tests. There is a research gap, even mentioned in the
study itself, regarding how collocation interacts with word-formation
processes, especially in this context. This study explains the what and
where, but being exploratory in nature, it does not mention the why.

### Verb Regularity

The aim of the study "Internal and External Dynamics in Language:
Evidence from Verb Regularity in a Historical Corpus of English" is to
investigate the relationship between internal and external factors
affecting the evolution of rules and exceptions in language,
specifically focusing on the how regular the past tense verbs in
American English are. The main findings of the study indicate that
although the language has a continuous influx of new verbs, the overall
amount of irregularity in the language remains relatively constant over
time. The study used the Corpus of Historical American English (CoHA),
which contains a balanced variety of written genres and more than 330
million words from the 1830–1989 period, each tagged for part of speech.
The analysis approach involved a quantitative examination of factors
contributing to language change, focusing on the effects of verb birth
and death, as well as the regularizing or irregularizing of existing
words. The study also used statistical methods to analyze the data,
including the proportion of irregularity as the number of irregular past
tense tokens over the total number of past tense tokens, and
frequency-rank plots for different verb types in all decades. There is a
research gap in that the study does not mention how certain words may
change regularity over time, and whether certain words are more
"volatile" than others.

### Ghanaian English Nativization

The aim of the study "Outdooring the Historical Corpus of English in
Ghana" by Thorsten Brato is to compile a historical corpus of Ghanaian
English (GhE) and to illustrate in real time how GhE has developed over
its nativization phase. The main findings of the study indicate that GhE
has been influenced by factors including: demographics, migration
patterns, and language attitudes, leading to deviations from the
developmental path suggested in the Dynamic Mode (I will not go into
depth about the Dynamic Mode here, for more information, see the
original study) . The study used the Historical Corpus of English in
Ghana (HiCE Ghana), a 600,000-word corpus of GhE from the period
1966–1975, and compared it with the written-printed sections of the
Ghanaian component of ICE (another corpus of GhE) to uncover how GhE has
changed over the last two generations. The analysis approach involved a
real-time comparison of empirical data and proposed adaptations where
necessary. The study also used statistical methods to analyze the data,
such as comparing data from ICE corpora of varieties which have
progressed to different phases and taking an apparent-time approach to
test developments within one variety. The findings contribute to a
nuanced understanding of the linguistic landscape in Ghana. There is a
research gap in that the study does not include other postcolonial
Englishes, which would help to compare the GhE findings against other
similar Englishes, to see if they are consistent to other observed
changes.

### Sociolinguistic Typology & Historical Corpus Linguistics

The aim of the study "Sociolinguistic Typology Meets Historical Corpus
Linguistics" is to showcase how the integration of historical corpora
into research methodologies can enrich our understanding of
sociolinguistic typology, as highlighted by three case studies exploring
potential morphosyntactic simplifications. These case studies delve into
the loss of number concordance in English, changes in Latin American
Spanish's null-subject system(s), and reductions in the case system in
Balkan Slavic, revealing that historical corpus evidence can effectively
contribute to addressing questions within sociolinguistic typology,
facilitating the testing of theoretical predictions and the
identification of new influencing factors. The dataset utilized in the
study comprises diverse texts ranging from Middle English horse
treatises to Bulgarian saints' lives to Afro-Colombian poetry, totaling
over 50 texts sourced from seven countries with AHLA-speaking
communities, alongside Spain as a control. The study makes use of
various historical corpora such as CDE, CORDE/CDH, and CORDIAM, in
addition to freely available texts from databases like Cervantes
Virtual, BDH, and DLOC. Methodologically, the research adopts the
"variationist" historical corpus method, which assesses the prevalence
of different linguistic variants across different times and places.
Statistical methods are employed to evaluate predictions, comparing
texts from various times and geographical contexts. The study also
addresses methodological challenges related to compiling and annotating
corpora, particularly in the context of null subjects, employing
techniques such as linear regression models and corpus balancing to
ensure homogeneity. There is a research gap regarding the "why" behind
this study, as these case studies are interesting, but this study simply
shows that corpus linguistics can be used in sociolinguistic contexts.
It does not show why the results are the way they are, or really what it
means for each case study individually.

### Historical Corpus Analysis of the Apostrophe in Written English

The aim of the study "The night before beg’d ye queens’s pardon and his
brother’s: the apostrophe in the history of English" by Javier
Calle-Martín and Marta Pacheco-Franco is to investigate the
standardization of the apostrophe in the English orthographic system in
the period 1600–1900. The study pursues the objectives of studying the
use and omission of the apostrophe in the expression of the past tense,
the genitive case, and the nominative plural in the period, assessing
the relationship between the three uses and their likely connections,
and evaluating the likely participation of grammarians in the adoption
and the rejection of each of these phenomena in English. The main
findings of the study indicate that the systematic adoption of the
apostrophe in the English punctuation is a late sixteenth-century
development, and the symbol quickly gained in popularity and acquired a
variety of functions that included the past tense (-’d), the genitive
case (-’s), and the nominative plural (-’s). The study also shows that
the possessive apostrophe was introduced earlier than accounted for in
the literature and had spread and overcome its counterpart by the early
eighteenth century. The study used the A Representative Corpus of
Historical English Registers (ARCHER 3.2) and the Early English Books
Online corpus (EEBO) as sources of evidence. The methodology involved
the extraction of data from these corpora, and the analysis of a total
of 166,550 instances from ARCHER and 836,805 instances from EEBO. The
study also used statistical methods to compare frequencies over time and
across genres, and to normalize the data to a common base of words. The
research gap lies in that the study does not note if those early uses of
apostrophes had different counterparts before the introduction of the
apostrophe, and if those uses have a history of being linguistically
volatile. According to the way the study has presented the information
and background, those uses would have had a minimum of two changes in
300 years, so it would call into question how often those uses change,
and even if there are similar parallels in other languages.

### Research Statement

The research gap that I have identified regards the scope of the
research in question. I believe that many of these studies explore
deeply into a very specific area. This allows these studies to crawl
through data that can explain the intricacies of the phenomena at hand,
but does not allow the studies to see the bigger picture. More data and
more varied data would allow these studies or another study to compare
phenomena between languages and contexts. This could lead to new
understanding of language development in context, for example. My
research question, thus, is: do postcolonial languages develop new words
at the same rate, or does the country's independence either slow or
hasten the divergence of postcolonial language? The objectives of this
research would be to answer whether or not postcolonial languages are
affected by a country's independence. The expected impact of this
research is to expand upon the current research in this area, and to
make connections between different languages and their divergence
through time. Perhaps concrete stages can be developed to give a general
guide about how postcolonial languages develop.

### Assessing progress

I learned how to identify a research gap, and how to craft a research
question around that gap. I found it challenging to read all of the
studies and analyze them, however just due to the amount of information
that was new to me. I didn't consult any resources for this process, as
all of the analyzing must be done by me. I do have a few questions that
pertain to my research question: is it detailed enough, or too much? Is
it supposed to be more connected with all 5 studies, or is it alright
that I just chose one to base it off of? I will need reassurance on
these questions to move forward.

# Methods

## Data preparation

### Ideal Data

The ideal data for the aforementioned research question needs to have
both the depth to faithfully represent the new words being written in
postcolonial Englishes, and have the width to be able to compare the
statistics gleaned from at least a few different languages. The dataset
will likely have to comprise multiple other datasets, which will likely
be hard to find. I anticipate having to merge a few datasets together,
making sure to retain as much information as possible, especially year
and location, as these will be most important to this analysis. Speaking
of the individual data, I would hope it is "tidy", with each row
representing a data point and each column telling information about the
data point. I hope that I am able to find data that is of written and
oral modalities, and although this project is focused on written
modalities moreso, if someone in the future wanted to expand my research
to oral modalities, I would hope the data I can find will support that
research. The ideal data would have the words already tokenized, with
their definitions in American English, along with their part of speech,
some measure of their popularity, the year they rose to prominence,
their modality, their country of origin, and perhaps the origin of the
word in question, including the gender and age of who wrote it, and the
document ID from which it came. The ideal dataset would be free to use
for my purposes, and would be available online. I would hope that people
who have postcolonial Englishes' best interests in mind had collected
the data, and that there were no ethical bounds crossed in this
collection. I also hope that these people were planning or already have
done some of their own research on this dataset as that would mean they
have a process for altering the data to fit their research question,
which might mean it is more tidy than it would be if it was collected
independently of any study.

### Available Data

The available data being considered will start with ICE Ghana and HiCE
Ghana, the two corpora used in "Outdooring the Historical Corpus of
English in Ghana". To get access to ICE Ghana, I would have to show a
valid license to use this data, and request access directly from the ICE
website. However, I can speak about its format without getting direct
access to the data. ICE Corpora are luckily structured in formulaic
ways. The written modalities of ICE Corpora are structured as follows:
out of 200 written texts, 50 are non-printed and 150 are printed. Of the
50 non-printed texts, 20 are student writing which includes 10 student
essays and 10 exam scripts, and 30 are letters, which includes 15 social
letters and 15 business letters. Of the 150 printed texts, 40 are
academic writing, which includes 10 texts each from humanities, social
sciences, natural sciences, and technology, 40 are popular writing,
which includes 10 from each of the same subjects, 20 are reportage,
namely press news reports, 20 are instructional writing (10
administrative writing, 10 skills/hobbies), 10 are persuasive writing,
namely press editorials, and the last 20 are creative writing, which is
comprised of novels and short stories. Clearly, ICE Corpora are very
well balanced, so this is ideal. HiCE Ghana is also hard to get direct
access to, however I have found that it is organized in much the same
way as ICE Ghana, simply expanding the years it has data from, and
adding more data to all fields. Without direct access to any of these
corpora, I cannot tell how well this data is aligned to my ideal data.
Other ICE and ICE ajacent corpora will also be considered, including ICE
East Africa, which include Kenya and Tanzania, ICE Jamaica, ICE
Philippines, ICE Nigeria and ICE Uganda. All will follow the same
general format, which will be useful when it comes time to merge these
datasets together.

### Resolving Misalignment

Without direct access to these datasets at this time, it is impossible
to know exactly how to fit the data into something more ideal. However,
I can speculate on what it would take to fit the data to my ideal data,
given that the ICE Corpora look similar to the data I have encountered
in this class so far. Firstly, and perhaps most importantly, the
tokenization into words. For any data to be useful to me in this
context, it would need to be tokenized, likely by words. If the text was
not tokenized in this way, I would need to do so. I would need to be
especially careful in this process, because the words or phrases being
used in these corpora could be unfamiliar to me, but especially
unfamiliar to whatever process is tokenizing the words. If these words
are written with dashes, for example, I would need to make sure to keep
them together, to preserve meaning, however, this could have other
unintended consequences in other circumstances. Once tokenized, the
words would need to be retained in order, and probably have a word-id
and document-id column, so that they could be reconstructed into a form
similar to the original text, if needed. This can be done with a simple
R function, and does not pose much of a problem. It would also be
important to note the modality of the data, so if that is not already a
part of this data, I would attempt to fix that. I imagine, though that
this is a part of the ICE corpora, along with the more specific use case
of the document the word comes from. I am not certain that the ICE
corpora would include information about the writer or speaker, but if
this is not included, it would be very difficult to restore this data,
as it would not be intertwined with any other data in this dataset. If
this is not included, I would have no choice but to do without it. The
country of origin would be easy to include, simply in that the corpora
are organized this way already. All I would have to do is add a column
to each corpus and note the country before merging the corpora together.
The year from when the word rose to prominence would be hard to obtain,
and would probably be a statistic in and of itself, rather than included
in the data. It would be useful to have the year the word was written,
then a histogram could be constructed, with the year on one axis and the
count of the word on the other, then the most popular year, or the first
year where the count of the word crossed a certain threshold could be
taken, and then added to the data as another column as
'year_of_prominence'. In this way, this data could be gleaned. The most
difficult column to restore, would be the part of speech. Luckily, many
ICE corpora have POS tags, so hopefully this wouldn't be an issue. If
the POS tag was not there, I would have to find a program, likely some
sort of AI, to classify these words. This would be largely difficult for
this AI, and it may get many words wrong, given that it was probably not
trained on post-colonial Englishes. I would have to test its
effectiveness in some way, and if its accuracy was below a certain
threshold, it would simply not be acceptable to use in this case, and I
would have to go without POS tags. Overall, although this is very
speculative, I don't believe that the whole process would be incredibly
difficult, as this plan seems to cover many possibilities.

### Assessing Progress

In this project step, I learned to think about what I would actually
want in my dataset, even before finding it. Before doing this step, I
had imagined that the opposite process was true, adapting a dataset to
fit your needs, but really, it helps much more to think about the
perfect dataset, and then finding something close to it. Most
challenging was the misalignment section, simply because it was very
speculative, because I don't have access to the data I would need. I do
have a question on whether or not it is necessary to have direct access
to this data to move on with this project. I'm fairly certain I could
gain access, it just may take some time. I would need to address this to
move forward.

My interests have evolved slightly since taking on this project.
Originally I wasn't sure what to do, but I had a few ideas, including
the following in my notes: - geographical boundaries of dialect vs.
languages - age of borders / national identity vs. sharpness of
boundaries of languages - head trauma vs. enunciation of words - foreign
word use through history compared to origin language My final bullet
point does have something to do with this prospectus, and my interests
have kept up with the direction of this project. My research question
has remained largely the same, however, I realize how difficult it would
be to keep the scope of this prospective study so large. It may be more
wieldy to focus the scope on just West Africa, as a more direct logical
step from the previous literature. Depending on the ease of obtaining
data, the scope would change. Overall, from reading and witnessing in
class how much it takes to get POS tags or to do data preparation, even
before any analyzing happens, I understand why it is so difficult to do
a study on a large scope.

## Data analysis

Why would we analyze data, though, without purpose? The purpose is as
follows: there is a need to extend the current application of existing
methods into new areas, making the scope of study larger to represent
more Englishes and more people, hopefully without sacrificing too much
granularity, as is the worry when expanding the scopes of such studies.
The study I am expanding upon, "Outdooring the Historical Corpus of
English in Ghana" is a very satisfactory case study on the English of
Ghana, but it would be advantageous to expand the study to include more
West African Englishes, to increase variation and attempt to find
evidence to support or to dissuade a hypothesis.

Attempting to support or contradict a trend like this would be
representative of inferential research. This means we are taking a
sample from a population, and all things being equal, the bigger the
sample, the better. We are hoping this sample faithfully represents the
population so that we can generalize trends present in the sample to the
larger population as a whole. My goals are very much similar. I have a
question I am asking, "do postcolonial languages develop new words at
the same rate, or does the country's independence either slow or hasten
the divergence of postcolonial language?", and thus I need to either
find evidence that supports this conclusion or does not support this
conclusion. I hope to find a result in this data, usually called a
p-value, that is above a certain threshold, and if it is above this
threshold it is not statistically significant, and if it is below this
threshold then it is statistically significant. Putting this in
statistical terms, this process is called a hypothesis test. A typical
p-value is 0.05, and for these purposes I believe it would be acceptable
to define our threshold as such.

### Analysis Plan

In this research study, it would be advantageous to use simulation-based
null hypothesis significance testing, as it is based on empirical data,
which we are assuming we have, and does not require any assumptions
about the data. This is beneficial because we would rather not assume
something that is incorrect and jeopardize the efficacy of the whole
study, and would rather simply check what we can about our data.
Additionally, it is much easier to communicate later, especially to
non-statisticians. To be more specific, I would use a bivariate
correlation statistical test, as the explanatory variable: the date of
independence, is numerical (number of years) so it can be compared
against a numerical response variable: the number of neologisms present
in the language as compared to American English, or the english of the
colonizing country.

Finding the number of neologisms, however, is another process that needs
to be defined and completed before a hypothesis can be tested. This
process would need to compile the words in a corpus and perform some
level of frequency analysis on them. This would then be plotted against
time, as in the level of usage over time, and if growth is above a
certain threshold, as well as having certain other factors, i.e. being a
content word, having a higher frequency than its baseline frequency,
etc. This process would be largely automated, but still verified to
ensure it would be reliable. These neologisms can be counted, year by
year to get our number to be tested for correlation against date of
independence.

### Assessing Progress

I learned how to define a plan for data analysis in practice, and how to execute that plan in theory. I also, frankly learned about hypothesis tests since it had been a while since I had reviewed them in depth. This was likely the most challenging part: defining exactly what I want to do before I do it. I typically take a very hands on approach to programming, and this is simply a more theoretical approach to programming, so this was relatively difficult for me. I do not think I need to address much to move forward, I believe I have a good conceptual grasp on where I am and where I need to be in the coming days. 
My interests, since last time have evolved only slightly, I have come to the realization that my scope was still too large, so narrowing it down to only encompass North African Englishes seems like a decent compromise between granularity and scope. My research question hasn't changed since last step, but the way I could directly answer it is now much more clear, due to the slides in class, and the readings outside of it. This step has probably been the most enlightening to me in this respect.

# Expected results

This section presents the hypothesized findings based on the research
question and analysis methods. It should include a clear statement of
the expected results and their potential implications for the field of
Linguistics and language science.

# Communication plan

This section describes the plan for reporting, presenting, and sharing
the results of the study. It should include a detailed description of
the intended audience for the study, the format of the final report, and
any plans for sharing the results with the broader community.

# Conclusion

This section provides a summary of the research proposal and its
potential impact on the field of Linguistics and language science. It
should include a clear statement of the significance of the research
question and the potential contributions of the study.

# References

This section includes a list of sources cited in the prospectus. It
should be formatted according to the citation style used in the field of
Linguistics and language science.

# Appendix {.appendix}

This section includes any additional information that is relevant to the
prospectus, such as data sources, code, or other supplementary
materials.
